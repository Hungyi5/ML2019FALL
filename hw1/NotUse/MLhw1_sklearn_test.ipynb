{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-OvNy23p4n7"
   },
   "source": [
    "## Noise adding for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Liq7POvhpMB-"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wj8ncPohhFZw"
   },
   "source": [
    "For Data Preprocessing, first we deal with anomaly data, basically data with wrong or invalid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3C1csUtng9c5"
   },
   "outputs": [],
   "source": [
    "def readdata(data):\n",
    "    \n",
    "\t# 把有些數字後面的奇怪符號刪除\n",
    "\tfor col in list(data.columns[2:]):\n",
    "\t\tdata[col] = data[col].astype(str).map(lambda x: x.rstrip('x*#A'))\n",
    "\tdata = data.values\n",
    "\t\n",
    "\t# 刪除欄位名稱及日期\n",
    "\tdata = np.delete(data, [0,1], 1)\n",
    "\t\n",
    "\t# 特殊值補0\n",
    "\tdata[ data == 'NR'] = 0\n",
    "\tdata[ data == ''] = 0\n",
    "\tdata[ data == 'nan'] = 0\n",
    "\tdata = data.astype(np.float)\n",
    "\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duSP2H-1iIUg"
   },
   "source": [
    "We flatten our data to be in such format (col: one hour/ per col, row: one feature/ per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMIcdKlghxbQ"
   },
   "outputs": [],
   "source": [
    "def extract(data):\n",
    "\tN = data.shape[0] // 18\n",
    "\n",
    "\ttemp = data[:18, :]\n",
    "    \n",
    "    # Shape 會變成 (x, 18) x = 取多少hours\n",
    "\tfor i in range(1, N):\n",
    "\t\ttemp = np.hstack((temp, data[i*18: i*18+18, :]))\n",
    "\treturn temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkG3UBm5jCbH"
   },
   "source": [
    "Since some data points (PM2.5) have anomaly values, which strongly effect our training result, we decide to abandon them. In our case, we define PM2.5 < 2 or > 100 as anomaly data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1i1dzcQjY3w"
   },
   "outputs": [],
   "source": [
    "def valid(x, y):\n",
    "\tif y <= 2 or y > 100:\n",
    "\t\treturn False\n",
    "\tfor i in range(9):\n",
    "\t\tif x[9,i] <= 2 or x[9,i] > 100:\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def parse2train(data):\n",
    "\tx = []\n",
    "\ty = []\n",
    "\t\n",
    "\t# 用前面9筆資料預測下一筆PM2.5 所以需要-9\n",
    "\ttotal_length = data.shape[1] - 9\n",
    "\tfor i in range(total_length):\n",
    "\t\tx_tmp = data[:,i:i+9]\n",
    "\t\ty_tmp = data[9,i+9]\n",
    "\t\tif valid(x_tmp, y_tmp):\n",
    "\t\t\tx.append(x_tmp.reshape(-1,))\n",
    "\t\t\ty.append(y_tmp)\n",
    "\t# x 會是一個(n, 18, 9)的陣列， y 則是(n, 1) \n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\treturn x,y\n",
    "\n",
    "def parse2test(data):\n",
    "\tx = []\n",
    "\t\n",
    "\ttotal_length = data.shape[1] // 9\n",
    "\tfor i in range(total_length):\n",
    "\t\tx_tmp = data[:,i*9:i*9+9]\n",
    "\t\tx.append(x_tmp.reshape(-1,))\n",
    "\t# x 會是一個(n, 18, 9)的陣列， y 則是(n, 1) \n",
    "\tx = np.array(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjQZ_3VekIO4"
   },
   "source": [
    "This is our gradient descent algorithm. **Adam** was implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcTr91tAkGgP"
   },
   "outputs": [],
   "source": [
    "def minibatch(x, y):\n",
    "    # 打亂data順序\n",
    "    index = np.arange(x.shape[0])\n",
    "    np.random.shuffle(index)\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "    \n",
    "    # 訓練參數以及初始化\n",
    "    batch_size = 64\n",
    "    lr = 1e-3\n",
    "    lam = 0.001\n",
    "    beta_1 = np.full(x[0].shape, 0.9).reshape(-1, 1)\n",
    "    beta_2 = np.full(x[0].shape, 0.99).reshape(-1, 1)\n",
    "    w = np.full(x[0].shape, 0.1).reshape(-1, 1)\n",
    "    bias = 0.1\n",
    "    m_t = np.full(x[0].shape, 0).reshape(-1, 1)\n",
    "    v_t = np.full(x[0].shape, 0).reshape(-1, 1)\n",
    "    m_t_b = 0.0\n",
    "    v_t_b = 0.0\n",
    "    t = 0\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    for num in range(1000):\n",
    "        for b in range(int(x.shape[0]/batch_size)):\n",
    "            t+=1\n",
    "            x_batch = x[b*batch_size:(b+1)*batch_size]\n",
    "            y_batch = y[b*batch_size:(b+1)*batch_size].reshape(-1,1)\n",
    "            loss = y_batch - np.dot(x_batch,w) - bias\n",
    "            \n",
    "            # 計算gradient\n",
    "            g_t = np.dot(x_batch.transpose(),loss) * (-2) +  2 * lam * np.sum(w)\n",
    "            g_t_b = loss.sum(axis=0) * (2)\n",
    "            m_t = beta_1*m_t + (1-beta_1)*g_t \n",
    "            v_t = beta_2*v_t + (1-beta_2)*np.multiply(g_t, g_t)\n",
    "            m_cap = m_t/(1-(beta_1**t))\n",
    "            v_cap = v_t/(1-(beta_2**t))\n",
    "            m_t_b = 0.9*m_t_b + (1-0.9)*g_t_b\n",
    "            v_t_b = 0.99*v_t_b + (1-0.99)*(g_t_b*g_t_b) \n",
    "            m_cap_b = m_t_b/(1-(0.9**t))\n",
    "            v_cap_b = v_t_b/(1-(0.99**t))\n",
    "            w_0 = np.copy(w)\n",
    "            \n",
    "            # 更新weight, bias\n",
    "            w -= ((lr*m_cap)/(np.sqrt(v_cap)+epsilon)).reshape(-1, 1)\n",
    "            bias -= (lr*m_cap_b)/(math.sqrt(v_cap_b)+epsilon)\n",
    "            \n",
    "\n",
    "    return w, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_once(path):\n",
    "    year1_pd = pd.read_csv(path)\n",
    "    year1 = readdata(year1_pd)\n",
    "    train_data = extract(year1)\n",
    "    return parse2train(train_data)\n",
    "    \n",
    "\n",
    "def read_once2(path1, path2):\n",
    "    # read y1\n",
    "    year1_pd = pd.read_csv(path1)\n",
    "    year1 = readdata(year1_pd)\n",
    "    train_data = extract(year1)\n",
    "    train_x, train_y = parse2train(train_data)\n",
    "    # Read y2\n",
    "    year2_pd = pd.read_csv(path2)    \n",
    "    year2 = readdata(year2_pd)\n",
    "    train_data2 = extract(year2)\n",
    "    train_x2, train_y2 = parse2train(train_data2)\n",
    "    \n",
    "    # concate\n",
    "    train_x = np.vstack((train_x,train_x2))\n",
    "    train_y = np.concatenate((train_y,train_y2))\n",
    "    return train_x, train_y\n",
    "# **Combine them together!**\n",
    "\n",
    "def read_test(path3):\n",
    "    testing_pd = pd.read_csv(path3)\n",
    "    testing = readdata(testing_pd)\n",
    "    testing_data = extract(testing)\n",
    "    return parse2test(testing_data)\n",
    "\n",
    "def read_item_list(path):\n",
    "    from collections import OrderedDict\n",
    "    year1_pd = pd.read_csv(path)\n",
    "    return list(OrderedDict.fromkeys(year1_pd.iloc[::,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKQ8D7FSnJiZ"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "path = './data/year2-data.csv'\n",
    "item_list = read_item_list(path)\n",
    "\n",
    "year_pd = pd.read_csv(path)\n",
    "year = readdata(year_pd)\n",
    "train_data = extract(year)\n",
    "train_x, train_y = parse2train(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding noise in data as regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38.43047691861617,\n",
       " 0.027521032583765977,\n",
       " 0.059790400636715244,\n",
       " 0.01164623556118513,\n",
       " 36.49385222355142,\n",
       " 102.65542733666418,\n",
       " 202.25939268103252,\n",
       " 369.1745158769626,\n",
       " 590.4693430078604,\n",
       " 7717.303667550197,\n",
       " 4.2946946263630865,\n",
       " 197.6025015319739,\n",
       " 5.525599986317008,\n",
       " 0.05338167208773795,\n",
       " 6141.835352129335,\n",
       " 6413.486185131539,\n",
       " 1.0198066240017931,\n",
       " 0.8722428033975521]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.var(train_data[i,::]) for i in range(len(train_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Tree_regressor = DecisionTreeRegressor(random_state=0)\n",
    "# cross_val_score(Tree_regressor, train_x, train_y, cv=10)\n",
    "\n",
    "Tree_regressor.fit(train_x, train_y)\n",
    "# read testing and pred\n",
    "test_path = './data/testing_data.csv'\n",
    "test_x = read_test(test_path)\n",
    "pred_y = Tree_regressor.predict(test_x)\n",
    "id_list = [ \"id_\"+str(i) for i in range(len(test_x))]\n",
    "\n",
    "output_pd = pd.DataFrame(zip(id_list, pred_y.ravel()), columns=['id', 'value'])\n",
    "output_name = './output/y2_tree_default.csv'\n",
    "output_pd.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id_0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id_1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id_2</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id_3</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id_4</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>id_495</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>id_496</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>id_497</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>id_498</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>id_499</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  value\n",
       "0      id_0   24.0\n",
       "1      id_1   11.0\n",
       "2      id_2   41.0\n",
       "3      id_3   20.0\n",
       "4      id_4   27.0\n",
       "..      ...    ...\n",
       "495  id_495   11.0\n",
       "496  id_496   15.0\n",
       "497  id_497   12.0\n",
       "498  id_498    9.0\n",
       "499  id_499   21.0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74935575, 0.75268889, 0.76563788, 0.74492853, 0.66472086,\n",
       "       0.63473952, 0.69333062, 0.76748318, 0.72358738, 0.80954346])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "Rand_forest_regr = RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                             n_estimators=100)\n",
    "\n",
    "cross_val_score(Rand_forest_regr, train_x, train_y, cv=10)\n",
    "# Rand_forest_regr.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76450798, 0.75357532, 0.76597157, 0.71782487, 0.19144676,\n",
       "       0.29981248, 0.53668613, 0.65906242, 0.44638515, 0.59183664])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_boost_regr = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "cross_val_score(ada_boost_regr, train_x, train_y, cv=10)\n",
    "\n",
    "\n",
    "# ada_boost_regr.fit(train_x, train_y)  \n",
    "# ada_boost_regr.feature_importances_  \n",
    "# ada_boost_regr.score(X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84972775, 0.82459689, 0.79439089, 0.7972529 , 0.75481918,\n",
       "       0.7749639 , 0.80292446, 0.85333585, 0.83318711, 0.88902308])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "r1 = LinearRegression()\n",
    "r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "\n",
    "\n",
    "er = VotingRegressor([('lr', r1), ('rf', r2)])\n",
    "cross_val_score(er, train_x, train_y, cv=10)\n",
    "\n",
    "# print(er.fit(X, y).predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85676701, 0.82525482, 0.79285547, 0.79573328, 0.74869566,\n",
       "       0.79259722, 0.80740053, 0.85774307, 0.84776547, 0.89180665])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "cross_val_score(lin_reg, train_x, train_y, cv=10)\n",
    "\n",
    "# lin_reg.score(train_x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7100, 162)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# stats.describe(train_data[0,::])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLhw1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
