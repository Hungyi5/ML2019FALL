{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-OvNy23p4n7"
   },
   "source": [
    "## Noise adding for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Liq7POvhpMB-"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wj8ncPohhFZw"
   },
   "source": [
    "For Data Preprocessing, first we deal with anomaly data, basically data with wrong or invalid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3C1csUtng9c5"
   },
   "outputs": [],
   "source": [
    "def readdata(data):\n",
    "    \n",
    "\t# 把有些數字後面的奇怪符號刪除\n",
    "\tfor col in list(data.columns[2:]):\n",
    "\t\tdata[col] = data[col].astype(str).map(lambda x: x.rstrip('x*#A'))\n",
    "\tdata = data.values\n",
    "\t\n",
    "\t# 刪除欄位名稱及日期\n",
    "\tdata = np.delete(data, [0,1], 1)\n",
    "\t\n",
    "\t# 特殊值補0\n",
    "\tdata[ data == 'NR'] = 0\n",
    "\tdata[ data == ''] = 0\n",
    "\tdata[ data == 'nan'] = 0\n",
    "\tdata = data.astype(np.float)\n",
    "\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duSP2H-1iIUg"
   },
   "source": [
    "We flatten our data to be in such format (col: one hour/ per col, row: one feature/ per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMIcdKlghxbQ"
   },
   "outputs": [],
   "source": [
    "def extract(data):\n",
    "\tN = data.shape[0] // 18\n",
    "\n",
    "\ttemp = data[:18, :]\n",
    "    \n",
    "    # Shape 會變成 (x, 18) x = 取多少hours\n",
    "\tfor i in range(1, N):\n",
    "\t\ttemp = np.hstack((temp, data[i*18: i*18+18, :]))\n",
    "\treturn temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkG3UBm5jCbH"
   },
   "source": [
    "Since some data points (PM2.5) have anomaly values, which strongly effect our training result, we decide to abandon them. In our case, we define PM2.5 < 2 or > 100 as anomaly data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1i1dzcQjY3w"
   },
   "outputs": [],
   "source": [
    "def valid(x, y):\n",
    "\tif y <= 2 or y > 100:\n",
    "\t\treturn False\n",
    "\tfor i in range(9):\n",
    "\t\tif x[9,i] <= 2 or x[9,i] > 100:\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def parse2train(data):\n",
    "\tx = []\n",
    "\ty = []\n",
    "\t\n",
    "\t# 用前面9筆資料預測下一筆PM2.5 所以需要-9\n",
    "\ttotal_length = data.shape[1] - 9\n",
    "\tfor i in range(total_length):\n",
    "\t\tx_tmp = data[:,i:i+9]\n",
    "\t\ty_tmp = data[9,i+9]\n",
    "\t\tif valid(x_tmp, y_tmp):\n",
    "\t\t\tx.append(x_tmp.reshape(-1,))\n",
    "\t\t\ty.append(y_tmp)\n",
    "\t# x 會是一個(n, 18, 9)的陣列， y 則是(n, 1) \n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\treturn x,y\n",
    "\n",
    "def parse2test(data):\n",
    "\tx = []\n",
    "\t\n",
    "\ttotal_length = data.shape[1] // 9\n",
    "\tfor i in range(total_length):\n",
    "\t\tx_tmp = data[:,i*9:i*9+9]\n",
    "\t\tx.append(x_tmp.reshape(-1,))\n",
    "\t# x 會是一個(n, 18, 9)的陣列， y 則是(n, 1) \n",
    "\tx = np.array(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjQZ_3VekIO4"
   },
   "source": [
    "This is our gradient descent algorithm. **Adam** was implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcTr91tAkGgP"
   },
   "outputs": [],
   "source": [
    "def minibatch(x, y):\n",
    "    # 打亂data順序\n",
    "    index = np.arange(x.shape[0])\n",
    "    np.random.shuffle(index)\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "    \n",
    "    # 訓練參數以及初始化\n",
    "    batch_size = 64\n",
    "    lr = 1e-3\n",
    "    lam = 0.001\n",
    "    beta_1 = np.full(x[0].shape, 0.9).reshape(-1, 1)\n",
    "    beta_2 = np.full(x[0].shape, 0.99).reshape(-1, 1)\n",
    "    w = np.full(x[0].shape, 0.1).reshape(-1, 1)\n",
    "    bias = 0.1\n",
    "    m_t = np.full(x[0].shape, 0).reshape(-1, 1)\n",
    "    v_t = np.full(x[0].shape, 0).reshape(-1, 1)\n",
    "    m_t_b = 0.0\n",
    "    v_t_b = 0.0\n",
    "    t = 0\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    for num in range(1000):\n",
    "        for b in range(int(x.shape[0]/batch_size)):\n",
    "            t+=1\n",
    "            x_batch = x[b*batch_size:(b+1)*batch_size]\n",
    "            y_batch = y[b*batch_size:(b+1)*batch_size].reshape(-1,1)\n",
    "            loss = y_batch - np.dot(x_batch,w) - bias\n",
    "            \n",
    "            # 計算gradient\n",
    "            g_t = np.dot(x_batch.transpose(),loss) * (-2) +  2 * lam * np.sum(w)\n",
    "            g_t_b = loss.sum(axis=0) * (2)\n",
    "            m_t = beta_1*m_t + (1-beta_1)*g_t \n",
    "            v_t = beta_2*v_t + (1-beta_2)*np.multiply(g_t, g_t)\n",
    "            m_cap = m_t/(1-(beta_1**t))\n",
    "            v_cap = v_t/(1-(beta_2**t))\n",
    "            m_t_b = 0.9*m_t_b + (1-0.9)*g_t_b\n",
    "            v_t_b = 0.99*v_t_b + (1-0.99)*(g_t_b*g_t_b) \n",
    "            m_cap_b = m_t_b/(1-(0.9**t))\n",
    "            v_cap_b = v_t_b/(1-(0.99**t))\n",
    "            w_0 = np.copy(w)\n",
    "            \n",
    "            # 更新weight, bias\n",
    "            w -= ((lr*m_cap)/(np.sqrt(v_cap)+epsilon)).reshape(-1, 1)\n",
    "            bias -= (lr*m_cap_b)/(math.sqrt(v_cap_b)+epsilon)\n",
    "            \n",
    "\n",
    "    return w, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_once(path):\n",
    "    year1_pd = pd.read_csv(path)\n",
    "    year1 = readdata(year1_pd)\n",
    "    train_data = extract(year1)\n",
    "    return parse2train(train_data)\n",
    "    \n",
    "\n",
    "def read_once2(path1, path2):\n",
    "    # read y1\n",
    "    year1_pd = pd.read_csv(path1)\n",
    "    year1 = readdata(year1_pd)\n",
    "    train_data = extract(year1)\n",
    "    train_x, train_y = parse2train(train_data)\n",
    "    # Read y2\n",
    "    year2_pd = pd.read_csv(path2)    \n",
    "    year2 = readdata(year2_pd)\n",
    "    train_data2 = extract(year2)\n",
    "    train_x2, train_y2 = parse2train(train_data2)\n",
    "    \n",
    "    # concate\n",
    "    train_x = np.vstack((train_x,train_x2))\n",
    "    train_y = np.concatenate((train_y,train_y2))\n",
    "    return train_x, train_y\n",
    "# **Combine them together!**\n",
    "\n",
    "def read_test(path3):\n",
    "    testing_pd = pd.read_csv(path3)\n",
    "    testing = readdata(testing_pd)\n",
    "    testing_data = extract(testing)\n",
    "    return parse2test(testing_data)\n",
    "\n",
    "def read_item_list(path):\n",
    "    from collections import OrderedDict\n",
    "    year1_pd = pd.read_csv(path)\n",
    "    return list(OrderedDict.fromkeys(year1_pd.iloc[::,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid2(x, y):\n",
    "\tif y <= 2 or y > 100:\n",
    "\t\treturn False\n",
    "\tfor i in range(9):\n",
    "\t\tif x[i] <= 2 or x[i] > 100:\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def parse2train2(data):\n",
    "\tx = []\n",
    "\ty = []\n",
    "\t\n",
    "\t# 用前面9筆資料預測下一筆PM2.5 所以需要-9\n",
    "\ttotal_length = data.shape[0] - 9\n",
    "\tfor i in range(total_length):\n",
    "\t\tx_tmp = data[i:i+9]\n",
    "\t\ty_tmp = data[i+9]\n",
    "\t\tif valid2(x_tmp, y_tmp):\n",
    "\t\t\tx.append(x_tmp.reshape(-1,))\n",
    "\t\t\ty.append(y_tmp)\n",
    "\t# x 會是一個(n, 18, 9)的陣列， y 則是(n, 1) \n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\treturn x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding noise in features for regularization\n",
    "**Noise in features!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1:抽全部9小時內的污染源feature當作一次項(加bias)\n",
    "Adding noise before parsing.\n",
    "\n",
    "### Case 2:抽全部9小時內pm2.5的一次項當作feature(加bias)\n",
    "只使用PM2.5當feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = '1'\n",
    "\n",
    "np.random.seed(0)\n",
    "path = './data/year2-data.csv'\n",
    "item_list = read_item_list(path)\n",
    "\n",
    "year_pd = pd.read_csv(path)\n",
    "year = readdata(year_pd)\n",
    "train_data = extract(year)\n",
    "test_path = './data/testing_data.csv'\n",
    "test_x = read_test(test_path)\n",
    "\n",
    "if case == '2':\n",
    "    train_data = train_data[9,::]\n",
    "    test_x = test_x[::,9*9:9*9+9]\n",
    "    train_x, train_y = parse2train2(train_data)\n",
    "else:\n",
    "    train_x, train_y = parse2train(train_data)\n",
    "# read testing and pred\n",
    "\n",
    "\n",
    "# Add noise here\n",
    "noise_level = 0.1\n",
    "for i in range(train_x.shape[1]):\n",
    "    train_x[::,i] = train_x[::,i] + np.random.normal(0, (np.var(train_x[::,i])*noise_level)**(1/2), len(train_x))\n",
    "\n",
    "# training\n",
    "w, bias = minibatch(train_x, train_y)\n",
    "pred_y = test_x @ w + bias\n",
    "\n",
    "id_list = [ \"id_\"+str(i) for i in range(len(test_x))]\n",
    "output_pd = pd.DataFrame(zip(id_list, pred_y.ravel()), columns=['id', 'value'])\n",
    "\n",
    "# output_name = './output/case' + case +'_y2_feature_noise0.1.csv'\n",
    "# output_pd.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7100, 162)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id_0</td>\n",
       "      <td>19.030662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id_1</td>\n",
       "      <td>17.898701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id_2</td>\n",
       "      <td>29.605728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id_3</td>\n",
       "      <td>13.527441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id_4</td>\n",
       "      <td>24.370929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>id_495</td>\n",
       "      <td>8.198283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>id_496</td>\n",
       "      <td>15.824962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>id_497</td>\n",
       "      <td>11.367833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>id_498</td>\n",
       "      <td>8.271553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>id_499</td>\n",
       "      <td>15.683836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      value\n",
       "0      id_0  19.030662\n",
       "1      id_1  17.898701\n",
       "2      id_2  29.605728\n",
       "3      id_3  13.527441\n",
       "4      id_4  24.370929\n",
       "..      ...        ...\n",
       "495  id_495   8.198283\n",
       "496  id_496  15.824962\n",
       "497  id_497  11.367833\n",
       "498  id_498   8.271553\n",
       "499  id_499  15.683836\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pd"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLhw1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
